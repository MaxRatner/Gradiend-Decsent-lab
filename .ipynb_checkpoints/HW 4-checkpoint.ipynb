{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import math\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "from joblib import Memory\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "mem = Memory(\"./mycache\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@mem.cache\n",
    "def get_data():\n",
    "    data = load_svmlight_file(\"mushrooms.txt\")\n",
    "    return data[0], data[1]\n",
    "\n",
    "matrix, y = get_data()\n",
    "A = matrix.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change target vector values to $\\{-1, 1\\}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1,  1]), array([3916, 4208]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.where(y==1, -1, 1)\n",
    "np.unique(y, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement Gradient Decsent for Logistic Regression function. Rephrased problem of minimization of Logistic regression function:\n",
    "\n",
    "$f(x) = \\dfrac{1}{n} \\sum_{i=1}^{n}(\\log(1 + \\exp(-y_{i}\\cdot(Ax)_{i})) + \\dfrac{\\mu}{2} \\| x \\|_{2}^{2})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x, mu):\n",
    "    Ax = np.matmul(A, x)\n",
    "    f = len(y)**(-1) * np.sum(np.log(1 + np.exp(-y * Ax)) + mu / 2 * x @ x)\n",
    "    return f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analitically find the gradient of $f(x)$ : <br>\n",
    "\n",
    "$\\nabla f(x) = \\bigg( \\dfrac{1}{n} \\sum_{i=1}^{n}\n",
    "\\big(\\dfrac{\\exp(-y_{i}\\cdot(Ax)_{i}) \\cdot A_{ij} \\cdot (-y_{i})} {(1 + \\exp(-y_{i}\\cdot(Ax)_{i})} + \\mu x_j \\big) \\bigg)_{j}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_f(x, mu):\n",
    "    Ax = np.matmul(A, x)\n",
    "    exp = np.exp(-y * Ax)\n",
    "    return (np.sum((exp / (1 + exp))[:, np.newaxis] * -y[:, np.newaxis] * A, axis=0) \\\n",
    "            + mu * x) / len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implement the gradient descent algorithm with different types of steps:\n",
    "1. Constant step <br> $\\alpha_{k} = \\alpha$\n",
    "2. Armijo rule step <br> If following is true for $\\alpha:$ <br>\n",
    "$ f(x_{k} + \\alpha h_{k}) - f(x_{k}) ≤\\varepsilon \\alpha \\langle \\nabla f(x_k), h_{k} \\rangle$, where $h_k = -\\nabla f(x_k); 0 < \\theta, \\varepsilon < 1$ <br>\n",
    "Otherwise try new $\\alpha = \\theta * \\alpha$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta, theta = np.random.rand(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_const_rule(alpha, x, mu):\n",
    "    return alpha\n",
    "    \n",
    "def armijo_rule(x_k, mu, alpha, eps):\n",
    "    grad_f = gradient_f(x_k, mu)\n",
    "    if f(x_k + np.multiply(-alpha, grad_f), mu) - f(x_k, mu) <= \\\n",
    "            eps * alpha * np.matmul(np.transpose(grad_f), np.multiply(-1, grad_f)):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def step_armijo_rule(alpha, x_k, mu):\n",
    "    while armijo_rule(x_k, mu, alpha, delta) == False:\n",
    "        alpha = delta*alpha\n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introduce the shutdown criterion based on the rate of correctly predicted answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criterion_answers_rate(x, rate):\n",
    "    return np.sum(np.where((A @ x) > 0, 1, -1) == y) > rate * len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gradient descend function:** <br>\n",
    "Repeat until the criterion is true or iterations limit reached <br>$ x_{k+1} = x_{k} - \\alpha_{k} \\cdot \\nabla f(x_{k})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(f, step_rule, criteria, rate, alpha, mu, x_k):\n",
    "    max_iter, iter_num = 5000, 0\n",
    "    \n",
    "    while (criteria(x_k, rate) == False and iter_num < max_iter): \n",
    "        alpha = step_rule(alpha, x_k, mu)\n",
    "        x_k = x_k - alpha * gradient_f(x_k, mu)\n",
    "        iter_num += 1\n",
    "\n",
    "    return x_k, iter_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup starting data with step $= 0.01$ and confidence rate 0,9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 10**(-2)\n",
    "N = 10**4\n",
    "x_0 = np.ones_like(A[1])\n",
    "mu = lambda N: np.max((A @ np.transpose(A)).diagonal()) / (4 * (N - 1))\n",
    "L = lambda N: N / (4*(N - 1)) * np.max((A @ np.transpose(A)).diagonal())\n",
    "rate = 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Launch GD with different step choice rule and compare results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(487, array([ 0.99760311,  0.97208204,  0.21447375,  0.71111679,  1.00044584,\n",
       "         0.13282826,  0.14708673,  0.27931515,  0.99760384,  0.60454469,\n",
       "         0.99298563,  0.93010413,  0.59325613,  0.58074374,  0.51440063,\n",
       "         0.94860746,  1.00044908,  1.00044908,  0.81522578,  0.65232685,\n",
       "         0.65272974, -0.6241787 ,  1.0013021 ,  0.88920688, -0.09460964,\n",
       "         0.97843098,  1.0013021 ,  0.94964117,  0.84996817,  0.72665354,\n",
       "         0.72665354,  0.98923352, -0.96068248, -0.90787849,  0.93642953,\n",
       "         0.11851881, -0.08996777,  0.19386639,  1.00006247,  0.73565993,\n",
       "         0.72228792,  0.96363783,  1.00000701,  0.93940286,  0.66345539,\n",
       "         0.98564291,  0.9755916 ,  0.86210885,  0.98682475, -0.01513029,\n",
       "         0.04368133,  0.99521396,  0.2232503 , -0.10682461,  0.91691077,\n",
       "         0.95668882,  0.22159524, -0.06804963,  0.91831599,  0.97843098,\n",
       "         0.77496734,  1.00004044,  1.00278465,  1.00002218,  0.77497686,\n",
       "         0.37972096,  0.12240104,  0.99520439,  0.97843098,  0.77492936,\n",
       "         1.0000409 ,  1.0028034 ,  1.00002218,  0.766641  ,  0.37992773,\n",
       "         0.13944105,  0.98631225, -0.97144865,  0.99520439,  1.00001093,\n",
       "        -0.96667584,  1.00001093,  0.95749484, -0.90737509,  0.97843098,\n",
       "         0.54425357,  0.97843098,  0.17365856,  0.3307998 ,  1.00140719,\n",
       "         1.00000515,  0.16623887,  0.87953189,  1.00000515,  0.87970843,\n",
       "         0.95694103,  1.00015309,  0.14596009,  1.00000515,  1.00079578,\n",
       "         0.96898535,  1.00082336,  0.78578586, -0.38696631,  0.65912574,\n",
       "         0.3781802 ,  0.59949164,  0.97910364,  0.71882383,  0.5091319 ,\n",
       "         0.84368451,  1.00013375]))"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gd_const, gd_const_iter = gradient_descent(f, step_const_rule, criterion_answers_rate, rate, \\\n",
    "                            alpha, mu(N), x_0)\n",
    "gd_const_iter, gd_const"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(487, array([ 0.99760311,  0.97208204,  0.21447375,  0.71111679,  1.00044584,\n",
       "         0.13282826,  0.14708673,  0.27931515,  0.99760384,  0.60454469,\n",
       "         0.99298563,  0.93010413,  0.59325613,  0.58074374,  0.51440063,\n",
       "         0.94860746,  1.00044908,  1.00044908,  0.81522578,  0.65232685,\n",
       "         0.65272974, -0.6241787 ,  1.0013021 ,  0.88920688, -0.09460964,\n",
       "         0.97843098,  1.0013021 ,  0.94964117,  0.84996817,  0.72665354,\n",
       "         0.72665354,  0.98923352, -0.96068248, -0.90787849,  0.93642953,\n",
       "         0.11851881, -0.08996777,  0.19386639,  1.00006247,  0.73565993,\n",
       "         0.72228792,  0.96363783,  1.00000701,  0.93940286,  0.66345539,\n",
       "         0.98564291,  0.9755916 ,  0.86210885,  0.98682475, -0.01513029,\n",
       "         0.04368133,  0.99521396,  0.2232503 , -0.10682461,  0.91691077,\n",
       "         0.95668882,  0.22159524, -0.06804963,  0.91831599,  0.97843098,\n",
       "         0.77496734,  1.00004044,  1.00278465,  1.00002218,  0.77497686,\n",
       "         0.37972096,  0.12240104,  0.99520439,  0.97843098,  0.77492936,\n",
       "         1.0000409 ,  1.0028034 ,  1.00002218,  0.766641  ,  0.37992773,\n",
       "         0.13944105,  0.98631225, -0.97144865,  0.99520439,  1.00001093,\n",
       "        -0.96667584,  1.00001093,  0.95749484, -0.90737509,  0.97843098,\n",
       "         0.54425357,  0.97843098,  0.17365856,  0.3307998 ,  1.00140719,\n",
       "         1.00000515,  0.16623887,  0.87953189,  1.00000515,  0.87970843,\n",
       "         0.95694103,  1.00015309,  0.14596009,  1.00000515,  1.00079578,\n",
       "         0.96898535,  1.00082336,  0.78578586, -0.38696631,  0.65912574,\n",
       "         0.3781802 ,  0.59949164,  0.97910364,  0.71882383,  0.5091319 ,\n",
       "         0.84368451,  1.00013375]))"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gd_armijo, gd_armijo_iter = gradient_descent(f, step_armijo_rule, criterion_answers_rate, rate, \\\n",
    "                             alpha, mu(N), x_0)\n",
    "gd_armijo_iter, gd_armijo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Implement stochastic GD.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find $\\nabla f_i(x)$, where $f_i$ - randomly choosen func from <br>\n",
    "$f(x) = \\dfrac{1}{n} \\sum_{i=1}^{n} f_i(x)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_f_i(x, mu, i):\n",
    "    Ax = A @ x\n",
    "    exp = np.exp(-y[i] * Ax[i])\n",
    "    return (-(exp / (1 + exp)) * A[i]) * y[i] + mu * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stoch_gd(f, step_rule, criteria, rate, alpha, mu, x_k):\n",
    "    max_iter, iter_num = 10000, 0\n",
    "    \n",
    "    while criteria(x_k, rate) == False and iter_num < max_iter: \n",
    "        alpha = step_rule(alpha, x_k, mu)\n",
    "        i = np.random.randint(len(y))\n",
    "        x_k = x_k - alpha * gradient_f_i(x_k, mu, i)\n",
    "        iter_num += 1\n",
    "    return x_k, iter_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000 # при больших слишком малые значения, получается nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(471, array([ 0.96568157,  0.96641696,  0.19500885,  0.71462636,  0.97702838,\n",
       "         0.11742451,  0.19154377,  0.22082399,  0.97555094,  0.59716606,\n",
       "         0.97555141,  0.92632399,  0.62301081,  0.52849467,  0.50184908,\n",
       "         0.91853013,  0.97555094,  0.9766884 ,  0.75139182,  0.66099914,\n",
       "         0.56284577, -0.5288629 ,  0.97671081,  0.85002244, -0.166284  ,\n",
       "         0.9657466 ,  0.97587913,  0.93478899,  0.79310535,  0.77118582,\n",
       "         0.76168431,  0.97555551, -0.94157263, -0.89678042,  0.93076329,\n",
       "         0.09545363, -0.06147075,  0.26197898,  0.97557109,  0.74840074,\n",
       "         0.7286244 ,  0.91757908,  0.97555094,  0.88499367,  0.55938069,\n",
       "         0.96574351,  0.97916024,  0.81695618,  0.97555275, -0.05894921,\n",
       "         0.09293208,  0.97555094,  0.18708549, -0.04249457,  0.86494289,\n",
       "         0.95602541,  0.11472893,  0.03396897,  0.88036144,  0.9657466 ,\n",
       "         0.73318914,  0.97555502,  0.97751997,  0.97555551,  0.71554314,\n",
       "         0.4499487 ,  0.09423041,  0.97555094,  0.9657466 ,  0.77319562,\n",
       "         0.97555502,  0.97700821,  0.97555551,  0.75348115,  0.40865943,\n",
       "         0.05808697,  0.97555094, -0.94156806,  0.97555094,  0.97555094,\n",
       "        -0.94157263,  0.97555551,  0.92681528, -0.88302807,  0.9657466 ,\n",
       "         0.4397642 ,  0.9657466 ,  0.25545849,  0.32297799,  0.97668841,\n",
       "         0.97555425,  0.13019368,  0.83516545,  0.97555159,  0.83585059,\n",
       "         0.92646504,  0.97558478,  0.23292314,  0.97555094,  0.97697296,\n",
       "         0.9559713 ,  0.97584011,  0.73149224, -0.35471636,  0.65062637,\n",
       "         0.35721051,  0.56044635,  0.94626463,  0.71414997,  0.57507572,\n",
       "         0.78294872,  0.97564167]))"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd, sgd_iter = stoch_gd(f, step_const_rule, criterion_answers_rate, rate, \n",
    "              alpha, mu(N), x_0)\n",
    "sgd_iter, sgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion_answers_rate(sgd, 0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Implement Nesterov Accelerated Gradient:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nesterov_gd(f, criteria, rate, mu, L, x_k, y_k):\n",
    "    max_iter, iter_num = 700, 0\n",
    "    x_next = y_k - 1/L * gradient_f(x_k, mu)\n",
    "    y_next = x_next + (math.sqrt(L) - math.sqrt(mu)) / (math.sqrt(L) + math.sqrt(mu)) * \\\n",
    "        (x_next - x_k)\n",
    "    \n",
    "    while (criteria(x_k, rate) == False and (iter_num < max_iter)): \n",
    "        x_next = y_k - 1/L * gradient_f(x_k, mu)\n",
    "        y_next = x_next + (math.sqrt(L) - math.sqrt(mu)) / (math.sqrt(L) + math.sqrt(mu)) * \\\n",
    "            (x_next - x_k)\n",
    "        x_k, y_k = x_next, y_next\n",
    "        iter_num += 1\n",
    "    return x_k, iter_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9.90433428e-01,  9.43382954e-01,  1.40728228e-01,  6.52839121e-01,\n",
       "        1.01838262e+00,  8.31156018e-02,  1.60288045e-01, -3.19271182e-02,\n",
       "        9.90479418e-01,  7.12495284e-01,  9.84099732e-01,  8.36519012e-01,\n",
       "        6.28876173e-01,  6.09469638e-01,  5.61302810e-01,  8.69290657e-01,\n",
       "        1.01476878e+00,  1.01476878e+00,  6.65895371e-01,  6.38983636e-01,\n",
       "        6.85677941e-01, -8.51888633e-01,  1.07366860e+00,  7.56481587e-01,\n",
       "       -4.38051965e-01,  9.23964029e-01,  1.07366860e+00,  1.41850472e+00,\n",
       "        6.51255233e-01,  6.82855308e-01,  6.82855308e-01,  9.61894246e-01,\n",
       "       -1.12810494e+00, -1.11327326e+00,  9.47062571e-01,  2.48319453e-01,\n",
       "       -4.14530144e-01,  7.05471319e-02,  1.00192471e+00,  6.76206806e-01,\n",
       "        6.54288457e-01,  9.66421433e-01,  9.99059573e-01,  1.00395499e+00,\n",
       "        6.72192160e-01,  9.50024100e-01,  1.02921441e+00,  8.44453405e-01,\n",
       "        9.53233734e-01, -3.61572106e-01,  1.95361414e-01,  9.82482962e-01,\n",
       "        3.48890098e-01, -3.54833723e-01,  8.54796291e-01,  9.21257916e-01,\n",
       "        2.63574829e-01, -2.55118578e-01,  9.01621462e-01,  9.23964029e-01,\n",
       "        7.24396459e-01,  1.00067709e+00,  1.07227052e+00,  9.99648215e-01,\n",
       "        7.24907075e-01,  3.97413903e-01, -4.23175233e-05,  9.81966461e-01,\n",
       "        9.23964029e-01,  7.24343476e-01,  1.00069350e+00,  1.07264309e+00,\n",
       "        9.99648215e-01,  7.33093211e-01,  3.98139994e-01,  4.44362806e-03,\n",
       "        9.68232284e-01, -1.16498385e+00,  9.81966461e-01,  9.99210688e-01,\n",
       "       -1.14905221e+00,  9.99210688e-01,  8.88011593e-01, -9.79413153e-01,\n",
       "        9.23964029e-01,  5.36715943e-01,  9.23964029e-01,  1.31392004e-01,\n",
       "        1.89953669e-01,  1.04808315e+00,  9.98989631e-01, -9.23516565e-02,\n",
       "        1.03101118e+00,  9.98989631e-01,  1.03821395e+00,  8.53226444e-01,\n",
       "        1.00650656e+00, -8.37393951e-03,  9.98989631e-01,  1.03148998e+00,\n",
       "        8.97675276e-01,  1.04742852e+00,  5.96420004e-01, -4.81545601e-01,\n",
       "        7.37413772e-01,  5.11215452e-01,  4.97124939e-01,  9.63581675e-01,\n",
       "        6.73685963e-01,  4.49821260e-01,  7.26673372e-01,  1.00555245e+00])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 10\n",
    "accelerated_gd, acc_iter = nesterov_gd(f, criterion_answers_rate, 0.95, mu(N), L(N), x_0, x_0)\n",
    "accelerated_gd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion_answers_rate(accelerated_gd, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
